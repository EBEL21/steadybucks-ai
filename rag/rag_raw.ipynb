{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install transformers==4.28.0 sentence-transformers==2.2.2 faiss-cpu datasets==2.13.0",
   "id": "24af8de7d7390388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:17:36.011331Z",
     "start_time": "2025-01-26T14:17:25.582905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 예시: AG News 데이터셋 (4개 카테고리의 뉴스 제목+본문)\n",
    "dataset = load_dataset(\"ag_news\", split=\"train[:1000]\")  # 샘플로 1000개만 사용\n",
    "dataset = dataset.to_pandas()  # Pandas로 변환\n",
    "dataset.head(3)"
   ],
   "id": "46131f7aecd9728d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:34:31.048644Z",
     "start_time": "2025-01-26T14:34:31.043549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.drop_duplicates()\n",
    "dataset.shape"
   ],
   "id": "74afaf34d4ca1468",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:35:47.024245Z",
     "start_time": "2025-01-26T14:35:47.021226Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "fba9a83c0ffd0e62",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:27:47.627758Z",
     "start_time": "2025-01-26T15:26:10.463762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "GENERATOR_MODEL_NAME = \"facebook/bart-large\"\n",
    "# GENERATOR_MODEL_NAME = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(GENERATOR_MODEL_NAME)\n",
    "generator_model = AutoModelForSeq2SeqLM.from_pretrained(GENERATOR_MODEL_NAME)\n"
   ],
   "id": "6ea00fb273466c2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd9245d0ba0849e5a84d8877d1d594ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kang\\.cache\\huggingface\\hub\\models--facebook--bart-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9e3ca23418a4ddb9c6775be257525b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42a1a33332a7408ca655483d763e1ea6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "948f3fec1ad642c9854e9b470f9689b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "792f7d5e0fe04a10b18b8f7de864beb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d86ca21fdaf74560867a9946a25f591b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e67457c373c4ac895fc7dedd98871c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:29:33.062797Z",
     "start_time": "2025-01-26T15:29:33.017346Z"
    }
   },
   "cell_type": "code",
   "source": "generator_model.to(torch.device(\"cuda\"))",
   "id": "5f5f888dcdde4a93",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mgenerator_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3110\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3105\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[0;32m   3106\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3107\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3108\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3109\u001B[0m         )\n\u001B[1;32m-> 3110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1337\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1338\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1340\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 900\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    903\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    904\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    905\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 900\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    903\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    904\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    905\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    923\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    924\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    925\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 927\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    930\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1320\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1321\u001B[0m             device,\n\u001B[0;32m   1322\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1323\u001B[0m             non_blocking,\n\u001B[0;32m   1324\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1325\u001B[0m         )\n\u001B[1;32m-> 1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1327\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1328\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1330\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1331\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mB:\\workspace\\TradingAI\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    314\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:34:47.040012Z",
     "start_time": "2025-01-26T14:34:44.573532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "QUERY_ENCODER_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "query_encoder = SentenceTransformer(QUERY_ENCODER_MODEL_NAME)\n"
   ],
   "id": "c1aac04bb4ad6dba",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:34:47.043183Z",
     "start_time": "2025-01-26T14:34:47.040521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_query(query: str):\n",
    "    # SentenceTransformers 모델로 임베딩 추출\n",
    "    embedding = query_encoder.encode([query], convert_to_numpy=True)\n",
    "    # shape: (384, )\n",
    "    return embedding[0]  \n"
   ],
   "id": "fcb34b1a79c1f3a6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:35:27.244584Z",
     "start_time": "2025-01-26T14:35:27.241371Z"
    }
   },
   "cell_type": "code",
   "source": "generator_model.device",
   "id": "ab0310fd448d79b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:40:20.112685Z",
     "start_time": "2025-01-26T14:40:20.101995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = encode_query(\"안녕하세요! 내일 날씨가 어떻습니까?\")\n",
    "tensor.shape"
   ],
   "id": "2841ff473fbe5a57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Document Indexing 코드 (FAISS 사용)",
   "id": "9f17f5aae8d98ccc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:43:06.326230Z",
     "start_time": "2025-01-26T14:43:02.769859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = dataset[\"text\"].tolist()  # list of strings\n",
    "doc_embeddings = query_encoder.encode(documents, convert_to_numpy=True)  # shape: (num_docs, dim)\n",
    "normalized_embeddings = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)"
   ],
   "id": "e19f17946c89c845",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:43:06.508111Z",
     "start_time": "2025-01-26T14:43:06.327299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dim = normalized_embeddings.shape[1]  # 임베딩 차원\n",
    "index = faiss.IndexFlatL2(dim)  # L2 거리기반\n",
    "index.add(normalized_embeddings)       # 문서 임베딩 등록"
   ],
   "id": "1b71ce8c3244f06e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:43:06.512218Z",
     "start_time": "2025-01-26T14:43:06.509168Z"
    }
   },
   "cell_type": "code",
   "source": "index.ntotal",
   "id": "c3f25415d3c0b05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Retriever 코드\n",
    "Retrieval 함수는 쿼리(텍스트)를 입력받아\n",
    "1. 쿼리 임베딩을 구하고\n",
    "2. FAISS index에서 유사 문서 Top-K를 찾고\n",
    "3. 해당 문서들의 텍스트를 반환한다."
   ],
   "id": "2d9fe81697ffe33f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:43:06.515789Z",
     "start_time": "2025-01-26T14:43:06.512730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_top_k_docs(query: str, k=3):\n",
    "    q_emb = encode_query(query).reshape(1, -1)  # (1, dim)\n",
    "    distances, indices = index.search(q_emb, k) # (1, k) shape\n",
    "    # indices: (1, k) 형태, 실제 문서 인덱스\n",
    "    top_k_docs = [documents[i] for i in indices[0]]\n",
    "    return top_k_docs, distances[0]\n"
   ],
   "id": "2b62b26a0d65da8c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:43:06.531601Z",
     "start_time": "2025-01-26T14:43:06.516293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_example = \"Find news about microsoft\"\n",
    "top_docs, dists = retrieve_top_k_docs(query_example, k=5)\n",
    "for i, (doc, dist) in enumerate(zip(top_docs, dists)):\n",
    "    print(f\"Top {i+1} doc (dist={dist:.4f}):\\n{doc}\\n\")\n"
   ],
   "id": "7751c80883d4743a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 doc (dist=0.7838):\n",
      "Taking the Microsoft Rorschach test CNET News.com's Charles Cooper asks what it is about Microsoft that pushes so many people straight over the edge?\n",
      "\n",
      "Top 2 doc (dist=0.8133):\n",
      "Microsoft to Introduce Cheaper Version of Windows  SEATTLE (Reuters) - Microsoft Corp. &lt;MSFT.O&gt; said it will  begin selling a stripped-down, low-cost version of its Windows  XP operating system in the emerging markets of Indonesia,  Malaysia and Thailand in order to spread the use of computing  and develop technology markets.\n",
      "\n",
      "Top 3 doc (dist=0.9460):\n",
      "Microsoft Lists XP SP2 Problems (NewsFactor) NewsFactor - With automatic download of Microsoft's (Nasdaq: MSFT) enormous SP2 security patch to the Windows XP operating system set to begin, the industry still waits to understand its ramifications. Home users that have their preferences set to receive operating-system updates as they are made available by Microsoft may be surprised to learn that some of the software they already run on their systems could be disabled by SP2 or may run very differently.\n",
      "\n",
      "Top 4 doc (dist=0.9588):\n",
      "Microsoft Upgrades Software for Digital Pictures  SEATTLE (Reuters) - Microsoft Corp. &lt;MSFT.O&gt; released on  Tuesday the latest version of its software for editing and  organizing digital photographs and images to tap into  widespread demand for digital cameras and photography.\n",
      "\n",
      "Top 5 doc (dist=1.0524):\n",
      "Microsoft Corp. 2.0: a kinder corporate culture Even a genius can mess up. Bill Gates was a brilliant technologist when he cofounded Microsoft , but as he guided it to greatness in both size and historical consequence, he blundered. He terrorized underlings with his temper and parceled out praise like Scrooge gave to charity. Only the lash inspired the necessary aggressiveness to beat the competition, he thought.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T16:14:54.958072Z",
     "start_time": "2025-01-24T16:14:54.954383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "for ch1, ch2 in zip(top_docs[0], top_docs[1]):\n",
    "    if ch1 != ch2:\n",
    "        print(i, ch1, ch2)\n",
    "    i = i+1"
   ],
   "id": "89bdfb148bcbf0b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 t n\n",
      "183 h e\n",
      "184 i x\n",
      "185 s t\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generator 코드",
   "id": "aaaf659e20f564f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:31:42.145913Z",
     "start_time": "2025-01-26T15:31:42.142388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rag_generate_answer(query: str, k=3, max_length=128):\n",
    "    # 1) Retrieval\n",
    "    top_docs, _ = retrieve_top_k_docs(query, k)\n",
    "    \n",
    "    context_str = \"\"\n",
    "    # 2) Context 만들기 (단순 예시)\n",
    "    for idx, doc in enumerate(top_docs):\n",
    "        context_str = context_str + f\"\\n[news no.{idx}]\\n{doc}\"\n",
    "    combined_prompt = f\"Question: {query}\\nContext: {context_str}\\nresult:\"\n",
    "    print(combined_prompt)\n",
    "    \n",
    "    # 3) Generator로 답 생성\n",
    "    inputs = generator_tokenizer([combined_prompt], return_tensors=\"pt\", truncation=True)\n",
    "    # GPU 사용 가능 시 -> inputs = inputs.to('cuda'), model도 .to('cuda') 가능\n",
    "    with torch.no_grad():\n",
    "        outputs = generator_model.generate(\n",
    "            **inputs, \n",
    "            max_length=max_length, \n",
    "            num_beams=2,\n",
    "            early_stopping=False,\n",
    "        )\n",
    "    answer = generator_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n"
   ],
   "id": "f9e76f0ed327cdae",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:31:47.112811Z",
     "start_time": "2025-01-26T15:31:42.464385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 예시 쿼리\n",
    "query_sample = \"when does google's auction open?\"\n",
    "answer_output = rag_generate_answer(query_sample, k=3)\n",
    "print(\"=== RAG-style Generation ===\")\n",
    "print(\"Query:\", query_sample)\n",
    "print(\"Answer:\", answer_output)"
   ],
   "id": "88d4688d6b0f2232",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: when does google's auction open?\n",
      "Context: \n",
      "[news no.0]\n",
      "Google auction begins on Friday An auction of shares in Google, the web search engine which could be floated for as much as \\$36bn, takes place on Friday.\n",
      "[news no.1]\n",
      "Google IPO Bidding Opens Google IPO Bidding Opens\\\\Google's IPO bidding is officially open. Google and its underwriters expect to open the auction for the shares of Google rsquo;s Class A common stock at 9:00 a.m. EST (press time) on Friday, August 13, 2004. Google bidders must have obtained a bidder ID from ipo.google.com if you ...\n",
      "[news no.2]\n",
      "In Google's Auction, It's Not Easy to Tell a Bid From a Bet In a competition combining suspense and strategy, countless brave souls are hoping to buy a small piece of Google in an auction this week.\n",
      "result:\n",
      "=== RAG-style Generation ===\n",
      "Query: when does google's auction open?\n",
      "Answer: Question: when does google's auction open?=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=---=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-----=-=-=-=-=-=-=-=-=-=-=-=---=-=-=---=-=--=----------------—---=----!------!--!----- ----- ------ ----- --- ----- --- -- ---- -- ---- -- - ---- - --- - -- -- -- -\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "745069c7aa62e6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
