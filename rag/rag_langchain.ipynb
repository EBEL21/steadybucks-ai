{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -U langchain langchain-openai langchain-community langchain-huggingface chromadb",
   "id": "7a6b812d351a248c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"practice-RAG\""
   ],
   "id": "ab6750b142564987",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "from dataclasses import dataclass\n",
    "import datasets"
   ],
   "id": "1374c8d5a90679c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LangChain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ],
   "id": "b2c54c805dc2824b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Logging Setup\n",
    "# ----------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"RAG-LangChain-Example\")"
   ],
   "id": "b3e6865d341eecb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ----------------------------------------------------------------------\n",
    "@dataclass\n",
    "class RAGConfig:\n",
    "    \"\"\"\n",
    "    Holds configuration variables for the RAG pipeline.\n",
    "    \"\"\"\n",
    "    dataset_name: str = \"ag_news\"           # Hugging Face dataset to load\n",
    "    dataset_split: str = \"train[:1000]\"     # only load a slice for demonstration\n",
    "    chunk_size: int = 512\n",
    "    chunk_overlap: int = 50\n",
    "    hf_embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    retrieval_qa_chat_prompt: str = \"langchain-ai/retrieval-qa-chat\" \n",
    "    vectorstore_persist_dir: str = \"./chroma_data\"\n",
    "    openai_model_name: str = \"gpt-4o-mini\"   # or \"gpt-4o\"\n",
    "    openai_temperature: float = 0.0\n",
    "    top_k: int = 3  \n",
    "    \n",
    "@dataclass\n",
    "class NewsDataItem:\n",
    "    \"\"\"\n",
    "    Represents a single news item with text and metadata.\n",
    "    \"\"\"\n",
    "    text: str\n",
    "    label: int"
   ],
   "id": "29fd380027c494ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset 로딩\n",
    "logger.info(f\"Loading dataset: {RAGConfig.dataset_name} [{RAGConfig.dataset_split}]\")\n",
    "ds = datasets.load_dataset(RAGConfig.dataset_name, split=RAGConfig.dataset_split)\n",
    "\n",
    "# Convert to a simpler python list of NewsDataItem\n",
    "data_items = []\n",
    "for row in ds:\n",
    "    data_items.append(NewsDataItem(text=row[\"text\"], label=row[\"label\"]))\n",
    "logger.info(f\"Loaded {len(data_items)} news items.\")"
   ],
   "id": "a5fd687f6622ee8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Document 생성\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=RAGConfig.chunk_size,\n",
    "    chunk_overlap=RAGConfig.chunk_overlap,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "# Convert each NewsDataItem to a Document\n",
    "docs = []\n",
    "for item in data_items:\n",
    "    # metadata example: store label\n",
    "    splitted = text_splitter.split_text(item.text)\n",
    "    for chunk in splitted:\n",
    "        docs.append(Document(page_content=chunk, metadata={\"label\": item.label}))\n",
    "\n",
    "logger.info(f\"Total chunked documents: {len(docs)}\")"
   ],
   "id": "aaea1f1ce9f8b72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "docs[52]",
   "id": "81ff9bf27ddc48af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ChromaDB 설정\n",
    "\n",
    "from chromadb.config import Settings\n",
    "logger.info(\"Initializing HuggingFace embeddings...\")\n",
    "embedding_fn = HuggingFaceEmbeddings(model_name=RAGConfig.hf_embedding_model)\n",
    "\n",
    "logger.info(\"Building Chroma vector store...\")\n",
    "\n",
    "# If you want persistence:\n",
    "vectorstore = Chroma.from_documents(\n",
    "    collection_name=\"news_collection\",\n",
    "    embedding=embedding_fn,\n",
    "    documents=docs,\n",
    "    persist_directory=RAGConfig.vectorstore_persist_dir,\n",
    "    client_settings=Settings(anonymized_telemetry=False)\n",
    ")"
   ],
   "id": "12d2cbad38bc792f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vectorstore.get(ids=\"5fab8d63-5fa0-4eeb-b328-38571818f8fb\")",
   "id": "573d6e468288182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Builds a RetrievalQA chain with an OpenAI LLM as generator.\n",
    "\"\"\"\n",
    "logger.info(\"Initializing OpenAI LLM and retrieval chain...\")\n",
    "_llm = ChatOpenAI(\n",
    "    model_name=RAGConfig.openai_model_name,\n",
    "    temperature=RAGConfig.openai_temperature\n",
    ")\n",
    "\n",
    "# Retrieve top-k docs\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": RAGConfig.top_k}\n",
    ")\n",
    "\n",
    "# pull prompt\n",
    "logger.info(\"Pull QA Chat Prompt from hub...\")\n",
    "_qa_prompt = hub.pull(f\"{RAGConfig.retrieval_qa_chat_prompt}\")\n",
    "\n",
    "# Build the chain\n",
    "logger.info(\"Creating RAG Chain...\")\n",
    "combine_docs_chain = create_stuff_documents_chain(_llm, _qa_prompt)\n",
    "_qa_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ],
   "id": "ab9773d0982b5fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "28cf6c1c426cd985",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LCEL 인터페이스 사용\n",
    "_qa_chain_lcel = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}\n",
    "    | _qa_prompt\n",
    "    | _llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "548fb2c9dc1bb760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_qa_chain_lcel.invoke(\"When does google open their auction?\")",
   "id": "7f08186b9be97d74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_qa_chain.invoke({\"input\": \"When does google open their auction?\"})",
   "id": "2d691c28aa418bd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ae77a5606bf0627f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
